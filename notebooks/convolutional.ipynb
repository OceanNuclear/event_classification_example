{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying simulated events using a Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, f1_score, \n",
    "                             matthews_corrcoef, roc_curve, roc_auc_score)\n",
    "from helper_functions import normalize_image_data, plot_history, plot_roc_auc\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and labels.\n",
    "DATA_PATH = \"../data/\"\n",
    "\n",
    "images = np.load(DATA_PATH+\"images_training.npy\")\n",
    "labels = np.load(DATA_PATH+\"labels_training.npy\")\n",
    "\n",
    "# Split the training indices into training and validation. \n",
    "# Validate with 25% of the data (default). Can be adjusted.\n",
    "x_idx = np.arange(images.shape[0])\n",
    "train_idx, val_idx, not_used1, not_used2 = train_test_split(x_idx, x_idx, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping data for CNNs\n",
    "The convolutional layers we'll be using expect the inputs to have 4 dimensions:\\\n",
    "(samples, M, N, channels).\\\n",
    "M and N are the image dimensions, 16x16, but while RGB images have 3 channels, ours currently has 0, but should have 1.\\\n",
    "We solve this by just adding an empty axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.reshape(images.shape[0], 16, 16, 1)\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "Now, you can build your own network from scratch, and that's a useful exercise. We're going to skip that\n",
    "here, and use one of the popular, exisiting frameworks that are widely used in current research.\n",
    "The most used base frameworks are [TensorFlow](https://www.tensorflow.org/), [PyTorch](https://pytorch.org/), and [Keras](https://keras.io/). Keras is a high-level API that abstracts a large amount of the process of building,\n",
    "training, and testing a model. You will need either TensorFlow or PyTorch, and the Keras API will automatically\n",
    "detect which base framework you have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and compile\n",
    "We base the initial model on a convolutional block in the [VGG16](https://arxiv.org/abs/1409.1556) architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Sequential model, and add layers to it.\n",
    "model = Sequential()\n",
    "\n",
    "# Initial model based on VGG16 conv block, reduced to 32 filters\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation = 'relu', input_shape= (16,16,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once the model is built, we need to compile it. This is where we specify the loss function,\n",
    "# optimizer, and any metrics we need, even custom ones.\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "This is the point where we normalize our data, just as we pass it to the training function of the model.\n",
    "The training run will display the progress as it goes through each batch.\n",
    "$$ \\text{num_batches} = \\frac{\\text{num_samples}}{\\text{batch_size}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for the training.\n",
    "batch_size = 32\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting validation data requires a tuple (val_input, val_targets). You can also just pass the\n",
    "# entire training set without splitting, and specify validation_split instead of validation_data.\n",
    "# The the model handles the splitting.\n",
    "\n",
    "val_data = (normalize_image_data(images[val_idx]), labels[val_idx])\n",
    "history = model.fit(\n",
    "    x=normalize_image_data(images[train_idx]),\n",
    "    y=labels[train_idx],\n",
    "    validation_data=val_data,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot history of loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function we stored in helper_functions.py\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collection of metrics\n",
    "* Accuracy\n",
    "* Confusion Matrix\n",
    "* F1-score\n",
    "* Matthews Correlation Coefficient\n",
    "* ROC-Curve and Area Under Curve\n",
    "\n",
    "Check out the notebook on logistic regression for details around the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the validation set\n",
    "pred = model.predict([normalize_image_data(images[val_idx])])\n",
    "# Convert sigmoid values from prediction to integers for the metric functions\n",
    "result = pred > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(labels[val_idx], result)\n",
    "confmat = confusion_matrix(labels[val_idx], result)\n",
    "f1 = f1_score(labels[val_idx], result)\n",
    "mcc = matthews_corrcoef(labels[val_idx], result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the metrics in an orderly fashion\n",
    "print(\"Confusion matrix:\\n\", confmat)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1-score:\", f1)\n",
    "print(\"MCC:\", mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC-curve and Area Under Curve\n",
    "### All events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_auc(labels[val_idx], pred)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
