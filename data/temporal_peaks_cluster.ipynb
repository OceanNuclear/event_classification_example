{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from temporal_peaks_cluster import *\n",
    "\n",
    "df = pd.read_csv('training_pm_nosat_150k.dat', sep=' ', header=None) # lazy way of reading the data\n",
    "num_events = df[0]\n",
    "# df[1] is just an integer 200. I don't know why.\n",
    "\n",
    "# Information which won't be available in the experimental data (i.e. labels)\n",
    "amp1, amp2 = df[2], df[7]\n",
    "rise1, rise2 = df[3], df[8]                 # default decay2=0\n",
    "decay1, decay2 = df[4], df[9]               # default pos2=0\n",
    "offset, pos1, pos2 = df[6], df[5], df[10]   # default pos2=0\n",
    "\n",
    "# Information which will actually be avialble in the experiment (i.e. features)\n",
    "wave_forms = df[df.columns[11:]]\n",
    "print('Data Read. Extracting useful information out of the data...')\n",
    "wave_forms.columns = range(wave_forms.shape[1])\n",
    "print(\"Renamed columns\")\n",
    "\n",
    "# Determine the standard deviation of the background\n",
    "stdev_bg = np.diff(wave_forms.T[:30], axis=0).std(axis=0)\n",
    "# when dealing with experimental data a more sophisticated method of determining the BG variation would be required,\n",
    "# since not all traces may have the first 30 values = background\n",
    "\n",
    "\n",
    "# classification step\n",
    "features = []\n",
    "for num, (ind, trace) in enumerate(wave_forms.iterrows()):\n",
    "    if num>30: # don't have time to classify all len(wave_forms) samples in this demo.\n",
    "        break\n",
    "    print(f'{ind=}, {amp1[ind]=}, {amp2[ind]=}',)\n",
    "    intersection_paths = scroll(trace.values, offset[ind], y_width=stdev_bg[ind])\n",
    "    point_cloud = intersection_paths[:,:]\n",
    "    minmax = MinMaxScaler()\n",
    "    # minmax.fit([[0,trace.min()],[len(trace),trace.max()]])\n",
    "    minmax.fit([[0,trace.min(), trace.min()],[len(trace),trace.max(), trace.max()]])\n",
    "    features.append(minmax.transform(point_cloud))\n",
    "    print(f'{len(intersection_paths)}')\n",
    "features, labels = ary(features), num_events.values\n",
    "\n",
    "\n",
    "# displaying the classification results\n",
    "for ind, feat in enumerate(features):\n",
    "    # !!!! DBSCAN requres tuning of the eps !!!!\n",
    "    dbs = DBSCAN(eps=0.1)\n",
    "    pred = dbs.fit_predict(feat)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.set_title(f'{ind}: {num_events[ind]} events')\n",
    "    for lab in range(pred.max()+1):\n",
    "        ax.scatter(*(feat[pred==lab]).T, label=f'label={lab} has {(pred==lab).sum()} points')\n",
    "    line = wave_forms.loc[ind].values\n",
    "    scaled_line = (line-line.min())/(line.max()-line.min())\n",
    "    plt.plot(np.linspace(0,1, len(scaled_line)), scaled_line, np.zeros(len(scaled_line)))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\"\"\"\n",
    "Verdict: \n",
    "Looks like this scroll appraoch is not very easy to use: \n",
    "1. the DBSCAN eps value needs tuning. \n",
    "2. the outputted labels require some filtering\n",
    "    (e.g. remove labels which occurs less than N times, where N=100? or N=len(feat)/30?\n",
    "    Or some other filtering condition depending on the location of the point cluster relative to the line?)\n",
    "3. Scolling algorithm parameter that we can tune:\n",
    "    3.1 use a different 'scrolling' algorithm: e.g. connect the furthest two cross-over points to extrapolate, instead of the nearest\n",
    "    3.2 width of the band used when 'scrolling'\n",
    "4. background determination method\n",
    "\n",
    "Log of failed methods:\n",
    "1. Other sklearn.cluster algorithms considered\n",
    "    OPTICS: Clearly doesn't work, divides into too many different clusters.\n",
    "    And I remember testing one of (SpectralClustering, AgglomerativeClustering) and it also doesn't work. \n",
    "Note: only these four algorithms were considered because the rest doesn't seem to recognize line clusters.\n",
    "2. \n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
