from numpy import array as ary; from numpy import log as ln
from numpy import cos, sin, pi, sqrt, exp, arccos;
tau = 2*pi
import numpy as np;
from matplotlib import pyplot as plt
import pandas as pd
from mpl_toolkits.mplot3d import Axes3D
from sklearn.cluster import DBSCAN, OPTICS, SpectralClustering, AgglomerativeClustering
from sklearn.preprocessing import MinMaxScaler
weak_source = 50
strong_source = 120

def cross_overs(series, constant):
    """
    Find the exact coordinates where the series crosses over the horizontal line y=constant.
    """
    above_bool = constant<series
    indices = np.where(np.diff(above_bool))[0]
    # we assume that the series starts and ends with non-zero values
    if constant<series[0]: indices = indices[1:]
    if constant<series[-1]: indices = indices[:-1]

    in_front = series[indices] - constant # difference between y_in_front and constant
    # behind = series[indices+1]
    x_offset = -in_front/np.diff(series)[indices] # (difference between y_in_front and constant) / (difference between y_in_front and y_behind)
    slope_sign = np.diff(above_bool.astype(int))[indices]
    return ary([x_offset+indices, np.full_like(indices, constant), slope_sign]).T

def find_intersection(trace, lower_thres, upper_thres):
    """
    Project the peak location of the trace using only the cross-over information of the series (crossing-over an upper and a lower threshold voltage).
    """
    lower = cross_overs(trace, lower_thres)
    upper = cross_overs(trace, upper_thres)
    xo_point_list = np.append(
                    np.append(lower, np.zeros(len(lower)).reshape([-1,1]), axis=1),
                    np.append(upper, np.ones(len(upper)).reshape([-1,1]), axis=1),
                    axis=0)
    x_ord = np.argsort(xo_point_list[:,0])
    xo_point_list = xo_point_list[x_ord] # re-order the list so that we can see which side came up first

    # organize the list into [points that rises] and [points that falls]
    rising = np.where(np.logical_and(np.diff(xo_point_list[:,2])==0, np.diff(xo_point_list[:,3])==1))[0]
    falling= np.where(np.logical_and(np.diff(xo_point_list[:,2])==0, np.diff(xo_point_list[:,3])==-1))[0]
    assert len(rising)==len(falling), "The program should detect the same number of rising and falling edges" # Otherwise I've written the program wrong
    cross_pt_list = []
    for ind1, ind3 in zip(rising, falling):
        (x1, y1), (x2, y2) = xo_point_list[ind1, :2], xo_point_list[ind1+1, :2]
        (x3, y3), (x4, y4) = xo_point_list[ind3, :2], xo_point_list[ind3+1, :2]
        m12 = (y2-y1)/(x2-x1)
        m34 = (y4-y3)/(x4-x3)
        cross_pt = np.linalg.solve([[-m12, 1], [-m34, 1]], [-m12*x1+y1, -m34*x3+y3])
        cross_pt_list.append(cross_pt)
    return cross_pt_list

def scroll(trace, offset, y_width, y_interval=1):
    """
    find the intersection points of the extrapolated lines, 
    where the extrapolated line is generated by examining the cross-over points with a reference horizontal line.
    As we scroll the reference horizontal line upwards, the location of these extrapolated intersection points will change.

    This function outputs a list of points where the first two coordinates = the location of the extrapolated intersection points,
    the last coordinate = the height of the reference horizontal line.
    """
    points = []
    for band_height in np.arange(offset+y_width, trace.max(), y_interval):
        intersection_points = find_intersection(trace, band_height-y_width/2, band_height+y_width/2)
        for point in intersection_points:
            points.append(point.tolist()+[band_height])
    return ary(points)

if __name__=='__main__':
    df = pd.read_csv('training_pm_nosat_150k.dat', sep=' ', header=None)
    num_events = df[0]
    # let's say the number of 
    # df[1] is just an integer 200. I don't know why.
    # Information which won't be available in the experimental data
    amp1, amp2 = df[2], df[7]
    rise1, rise2 = df[3], df[8]                 # default decay2=0
    decay1, decay2 = df[4], df[9]               # default pos2=0
    offset, pos1, pos2 = df[6], df[5], df[10]   # default pos2=0
    # Information which will actually be avialble in the experiment
    wave_forms = df[df.columns[11:]]
    print('Data Read. Extracting useful information out of the data...')
    wave_forms.columns = range(wave_forms.shape[1])
    print("Renamed columns")

    """ #unused step, we don't need
    np.random.seed(0)
    noise = np.random.normal(size = wave_forms.shape)
    noisy_wave = wave_forms + weak_source*noise
    """
    # Determine the standard deviation of the background

    features = []
    stdev_bg = np.diff(wave_forms.T[:30], axis=0).std(axis=0)
    # when dealing with experimental data a more sophisticated method would be required since not all traces would have the first 30 values = background
    for num, (ind, trace) in enumerate(wave_forms.iterrows()):
        if num>30:
            break
        print(f'{ind=}, {amp1[ind]=}, {amp2[ind]=}',)
        intersection_paths = scroll(trace.values, offset[ind], y_width=stdev_bg[ind])
        point_cloud = intersection_paths[:,:]
        minmax = MinMaxScaler()
        # minmax.fit([[0,trace.min()],[len(trace),trace.max()]])
        minmax.fit([[0,trace.min(), trace.min()],[len(trace),trace.max(), trace.max()]])
        features.append(minmax.transform(point_cloud))
        print(f'{len(intersection_paths)}')
        # fig = plt.figure()
        # ax = fig.add_subplot(111, projection='3d')
        # ax.scatter(*intersection_paths.T, alpha=0.3, marker='+')
        # plt.title(f'{ind=}, {amp1[ind]=}, {amp2[ind]=}',)
        # ax.plot(np.arange(len(trace)), trace.values, np.full_like(trace.values, offset[ind]), color='C1')
        # plt.show()
    features, labels = ary(features), num_events.values

    # DBSCAN requres tuning of the eps

    for ind, feat in enumerate(features):
        dbs = DBSCAN(eps=0.1)
        pred = dbs.fit_predict(feat)
        fig = plt.figure()
        ax = fig.add_subplot(111, projection='3d')
        ax.set_title(f'{ind}: {num_events[ind]} events')
        for lab in range(pred.max()+1):
            ax.scatter(*(feat[pred==lab]).T, label=f'label={lab} has {(pred==lab).sum()} points')
            # plt.plot(np.arange(len(wave_forms.loc[ind].values)), wave_forms.loc[ind].T, wave_forms.loc[ind].values[:,1].min())
        line = wave_forms.loc[ind].values
        scaled_line = (line-line.min())/(line.max()-line.min())
        plt.plot(np.linspace(0,1, len(scaled_line)), scaled_line, np.zeros(len(scaled_line)))
        plt.legend()
        plt.show()

    # spectral clustering, AgglomerativeClustering, and OPTICS don't work 
    # spec_clus = SpectralClustering(n_cluster=2)
    # spec_clus.fit_predict(features[0])
    # for lab in range(pred.max()+1):
    #     plt.scatter(*features[0][pred==lab].T)
    # plt.show()

    # from sklearn.model_selection import train_test_split
    
    # train_index, test_index, _, _ = train_test_split(np.arange(len(features)), np.arange(len(features)), test_size=0.1)
    """
    Verdict: 
    Looks like this scroll appraoch is not very easy to use: 
    1. the DBSCAN eps value needs tuning. 
    2. the outputted labels require some filtering (e.g. remove labels which occurs less than 100 time)
    """